{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac8bfe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_index in d:\\qasystem\\venv\\lib\\site-packages (0.12.32)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.32 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.12.32)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.6.11)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.3.38)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\qasystem\\venv\\lib\\site-packages (from llama_index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.75.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\qasystem\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (3.11.18)\n",
      "Requirement already satisfied: banks<3.0.0,>=2.0.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.1.2)\n",
      "Requirement already satisfied: dataclasses-json in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.2.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2025.3.2)\n",
      "Requirement already satisfied: httpx in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (3.2.1)\n",
      "Requirement already satisfied: numpy in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.11.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (4.13.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.32->llama_index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (0.1.18)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (4.13.4)\n",
      "Requirement already satisfied: pandas in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (5.4.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in d:\\qasystem\\venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.12)\n",
      "Requirement already satisfied: click in d:\\qasystem\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\qasystem\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\qasystem\\venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\qasystem\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.20.0)\n",
      "Requirement already satisfied: griffe in d:\\qasystem\\venv\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.7.2)\n",
      "Requirement already satisfied: jinja2 in d:\\qasystem\\venv\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.1.6)\n",
      "Requirement already satisfied: platformdirs in d:\\qasystem\\venv\\lib\\site-packages (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (4.3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\qasystem\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.7)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in d:\\qasystem\\venv\\lib\\site-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.1.31)\n",
      "Requirement already satisfied: anyio in d:\\qasystem\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\qasystem\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.8)\n",
      "Requirement already satisfied: idna in d:\\qasystem\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\qasystem\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.14.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.12 in d:\\qasystem\\venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (0.6.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\qasystem\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in d:\\qasystem\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama_index) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\qasystem\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in d:\\qasystem\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\qasystem\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\qasystem\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\qasystem\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\qasystem\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.2.0)\n",
      "Requirement already satisfied: colorama in d:\\qasystem\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.32->llama_index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\qasystem\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\qasystem\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\qasystem\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\qasystem\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\qasystem\\venv\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (2025.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\qasystem\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.32->llama_index) (1.2.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in d:\\qasystem\\venv\\lib\\site-packages (from llama-cloud-services>=0.6.12->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index) (1.1.0)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\qasystem\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.32->llama_index) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\qasystem\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama_index) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\qasystem\\venv\\lib\\site-packages (from jinja2->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.32->llama_index) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db19f067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd76d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6fbe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api key found\n"
     ]
    }
   ],
   "source": [
    "if google_api_key==\"\":\n",
    "    print(\"api key not found\")\n",
    "else:\n",
    "    print(\"api key found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c937b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "import google.generativeai as genai\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef947a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a289349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n"
     ]
    }
   ],
   "source": [
    "for models in genai.list_models():\n",
    "    if 'generateContent' in models.supported_generation_methods:\n",
    "        print(models.name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ae30bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=SimpleDirectoryReader(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ef3fc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=document.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2982db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "214656ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anupa Dutta Roy\\AppData\\Local\\Temp\\ipykernel_15364\\4148756438.py:1: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  gemini_embed_model=GeminiEmbedding(model_name=\"models/embedding-001\")\n"
     ]
    }
   ],
   "source": [
    "gemini_embed_model=GeminiEmbedding(model_name=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c99eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anupa Dutta Roy\\AppData\\Local\\Temp\\ipykernel_15364\\2064106326.py:1: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  model=Gemini(models=\"gemini-pro\",api_key=google_api_key)\n"
     ]
    }
   ],
   "source": [
    "model=Gemini(models=\"gemini-pro\",api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d66f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anupa Dutta Roy\\AppData\\Local\\Temp\\ipykernel_15364\\894485638.py:1: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  model=Gemini(models=\"gemini-pro\",api_key=google_api_key)\n",
      "C:\\Users\\Anupa Dutta Roy\\AppData\\Local\\Temp\\ipykernel_15364\\894485638.py:2: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
      "  gemini_embed_model = GeminiEmbedding(model_name=\"models/embedding-001\")\n"
     ]
    }
   ],
   "source": [
    "model=Gemini(models=\"gemini-pro\",api_key=google_api_key)\n",
    "gemini_embed_model = GeminiEmbedding(model_name=\"models/embedding-001\")\n",
    "\n",
    "# Configure LlamaIndex settings\n",
    "Settings.llm = model\n",
    "Settings.embed_model = gemini_embed_model\n",
    "Settings.chunk_size = 800\n",
    "Settings.chunk_overlap = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbc12f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=VectorStoreIndex.from_documents(doc,Settings=Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3d1b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "778772d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf7f9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=query_engine.query(\"Can you tell me about the origin of Dinosaurs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88ac7f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, but the context does not contain information about the origin of Dinosaurs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
